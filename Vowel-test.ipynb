{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "path = \"C:\\\\Users\\\\....\"    #path to output files\n",
    "alpha = 0.5     # learning rate\n",
    "num_iterations = 50     #epochs\n",
    "init = 0.9000   # setiing paricular weight to certain value\n",
    "init_words = 'point 9'  \n",
    "# perturb = 0.001    # adidng perturbation to the weight\n",
    "lip_lr = False   # adaptive learning rate\n",
    "loss = 'cross_entropy'   # 'cross_entropy' |  'mse'\n",
    "trials = 10     # number of independent trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#utility functions\n",
    "def prepare_data():\n",
    "    \"\"\"Reads and prepares the data the data has to be \n",
    "    in the same folder on which the program is running\n",
    "    \n",
    "    Commpleted\"\"\"\n",
    "    data = pd.read_csv(\"data.csv\")\n",
    "    data = np.array(data)\n",
    "    m,n = data.shape\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    data_dev = data[:741].T\n",
    "\n",
    "    Y_dev = data_dev[3]\n",
    "    X_dev = data_dev[:3]\n",
    "\n",
    "    data_train = data[741:m].T\n",
    "\n",
    "    Y_train = data_train[3]\n",
    "    X_train = data_train[:3]\n",
    "    \n",
    "    return X_train,Y_train,X_dev,Y_dev\n",
    "\n",
    "\n",
    "\n",
    "def init_params():\n",
    "    \"\"\"Makes the nn and return the paramters\n",
    "    W1 is the weights of layer 1 b1 is the bias and similarly for 2nd\n",
    "    2 layer network \n",
    "    input layer is of size 3\n",
    "    1st hidden layer has 4 neurons\n",
    "    2nd hidden layer has 6 neurons\n",
    "    1 Output neuron\n",
    "\n",
    "    Completed\"\"\"\n",
    "    W1 = np.random.randn(4,3)\n",
    "    b1 = np.random.randn(4,1)\n",
    "    W2 = np.random.randn(6,4)\n",
    "    b2 = np.random.randn(6,1)\n",
    "    return W1,b1,W2,b2\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Returns sigmoid of a value\n",
    "    Input: takes some value or an array of values\"\"\"\n",
    "\n",
    "\n",
    "    return \n",
    "\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \"\"\"Returns the value of the derivative of a a sigmoid\n",
    "    Input: takes some value or an array of values\"\"\"\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "def softmax(Z):\n",
    "    \"\"\"Returns sigmoid of an array\n",
    "    Input: takes an array of values\"\"\"\n",
    "\n",
    "\n",
    "    return \n",
    "\n",
    "\n",
    "def one_hot(Y):\n",
    "    \"\"\"Returns one hot encoding of the Output labels\n",
    "    Completed\"\"\"\n",
    "    one_hot_Y = np.eye(6)[Y-1]\n",
    "    return one_hot_Y.T\n",
    "  \n",
    "    \n",
    "def forward_prop(W1,b1,W2,b2,X):\n",
    "    \"\"\"Perform one forward propogation and return the outputs\n",
    "    Input: Takes the weights and biases of all layers and the data to pass thorugh them\n",
    "    Returns the Weighted sum and the activations \"\"\"\n",
    "    Z1 = \n",
    "    A1 = \n",
    "    Z2 = \n",
    "    A2 = \n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "\n",
    "def back_prop(Z1,A1,Z2,A2,W2,X,Y,func):\n",
    "    \"\"\"Performs one itertaion of back prop and returns the gradients\n",
    "    Input: Takes the weighted sum and activations of each layer,the data and labels, and the loss function\n",
    "    Returns the gradient for the neurons\"\"\"\n",
    "    X = X.reshape(-1,1)\n",
    "    m = Y.size\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    if func == 'cross_entropy':\n",
    "        dZ2 = \n",
    "    elif func == 'mse':\n",
    "        dZ2 = \n",
    "\n",
    "    dW2 =\n",
    "    db2 =\n",
    "    dZ1 =\n",
    "    dW1 =\n",
    "    db1 =\n",
    "    return dW1,db1,dW2,db2\n",
    "\n",
    "\n",
    "def update_params(W1,b1,W2,b2,dW1,db1,dW2,db2,alpha):\n",
    "    \"\"\"Update parameters and return them\n",
    "    Input: weights and biases and their gradients with the learning rate\n",
    "    Returns the updated weights and biases\"\"\"\n",
    "    W1 -= \n",
    "    b1 -= \n",
    "    W2 -= \n",
    "    b2 -= \n",
    "    return W1,b1,W2,b2\n",
    "    \n",
    "    \n",
    "def compute_cost(actual,pred,func):\n",
    "    \"\"\"Calculate and return cost\n",
    "    Input: predicted values and true values with the loss fucntion specified\n",
    "    Returns the cost\"\"\"\n",
    "    if func == 'cross_entropy':\n",
    "        J = \n",
    "        return (-1)*J\n",
    "    elif func == 'mse':\n",
    "        J = \n",
    "        return J\n",
    "    else:\n",
    "        return \"check loss func\"\n",
    "\n",
    "\n",
    "def populate_list(W1,w):\n",
    "    \"\"\"Stores the weights to a list\n",
    "    Input: the weight and the list to append it to\n",
    "    Returns the list, updated with the weight\"\"\"\n",
    "    norm = W1.reshape(1,-1)\n",
    "    norm = norm[0]\n",
    "    for i in range(len(norm)):\n",
    "        w[i].append(norm[i])\n",
    "    return w\n",
    "\n",
    "def accuracy(Y_train,X_test,*args):\n",
    "    \"\"\"Calculates accuracy and returns it\n",
    "    Input: Data and labels to get score from along with the model parameters\n",
    "    Returns the accuracy\n",
    "\n",
    "    Completed\"\"\"\n",
    "    \n",
    "    correct = 0\n",
    "    for i in range(X_test.shape[1]):\n",
    "        \n",
    "        z1, a1, z2, a2 = forward_prop(args[0], args[1],args[2],args[3],X_test[:,i])\n",
    "        y_res = one_hot(Y_train[i]).reshape(-1,1)\n",
    "        y_pred = np.floor(a2+0.5)\n",
    "        if(np.array_equal(y_pred,y_res)):\n",
    "            correct+=1\n",
    "    # print(f\"correct predictions:{correct}/{X_test.shape[1]}\")\n",
    "    return correct/X_test.shape[1]\n",
    "    \n",
    "def write_csv(df,name,trial,path):\n",
    "    \"\"\"Writes weights to csv\n",
    "    Input: dataframe to save, the trial number and the path to save it to\n",
    "    Returns nothing\n",
    "    \n",
    "    Completed\"\"\"\n",
    "\n",
    "    fname = name+'_'+str(trial)+'.csv' # 'W2_1' |  name = W2 or A2 or acc\n",
    "    fpath = path+init_words+'\\\\'+name+'\\\\'+fname\n",
    "    df.to_csv(fpath,index=False,header=False)\n",
    "\n",
    "# def read_weights(trial,list_weights):\n",
    "#     W1 = list_weights[trial-1][0]\n",
    "#     b1 = list_weights[trial-1][1]\n",
    "#     W2 = list_weights[trial-1][2]\n",
    "#     b2 = list_weights[trial-1][3]\n",
    "#     return W1,b1,W2,b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network(trial,X_train,Y_train,X_dev,Y_dev,l_rate,num_iterations,init,perturb,lip_lr,loss):\n",
    "\n",
    " ######################## Weight initialization\n",
    "  \n",
    "    W1,b1,W2,b2 = init_params() \n",
    "    \n",
    "    # W1, b1, W2, b2 = read_weights(trial,listWeights)\n",
    "\n",
    "    \n",
    "\n",
    "    w1 = {k:[] for k in range(W1.shape[0]*W1.shape[1])}\n",
    "    w2 = {k:[] for k in range(W2.shape[0]*W2.shape[1])}\n",
    "  \n",
    "\n",
    "    activations = {k:[] for k in range(4)}\n",
    "    \n",
    "    X_dev = min_max_scaler.fit_transform(X_dev.T)\n",
    "    X_dev = X_dev.T\n",
    "\n",
    "    X_test = min_max_scaler.fit_transform(X_train.T)\n",
    "    X_test = X_test.T\n",
    "\n",
    "    W1[0][0] = init\n",
    "    # W_init_1[0][0] = init + perturb  # creating another instance that has perturbed weights\n",
    "\n",
    "    cost = []\n",
    "    error = 0\n",
    "###########################################\n",
    "\n",
    "\n",
    "######################### without peturbation\n",
    "    for i in range(num_iterations):\n",
    "        for j in range(X_dev.shape[1]):\n",
    "            \n",
    "            if lip_lr:\n",
    "                l_rate = 2/(np.linalg.norm(X_dev[:,j]))\n",
    "\n",
    "            z1, a1, z2, a2 = forward_prop(W1, b1,W2,b2,X_dev[:,j])\n",
    "            dW1,db1,dW2,db2 = back_prop(z1,a1,z2,a2,W2,X_dev[:,j],Y_dev[j],loss)\n",
    "            \n",
    "            W1,b1,W2,b2 = update_params(W1,b1,W2,b2,dW1,db1,dW2,db2,l_rate)\n",
    "        \n",
    "            populate_list(W1,w1)   \n",
    "            populate_list(W2,w2)\n",
    "            activations[0].append(a1[0].item())\n",
    "            activations[1].append(a1[1].item())\n",
    "            activations[2].append(a1[2].item())\n",
    "            activations[3].append(a1[3].item())\n",
    "            y_train = one_hot(Y_dev[j]).reshape(-1,1)\n",
    "            y_pred = a2\n",
    "            c = compute_cost(y_train,y_pred,loss)\n",
    "            error += c/(X_dev.shape[1])\n",
    "            # acc.append(accuracy(Y_train,X_test,W1, b1,W2,b2))\n",
    "            # train_acc.append(accuracy(Y_dev,X_dev,W1,b1,W2,b2))\n",
    "\n",
    "        cost.append(error)\n",
    "        error = 0\n",
    "        \n",
    "\n",
    "    df_activations = pd.DataFrame.from_dict(activations)\n",
    "    df_w2 = pd.DataFrame.from_dict(w2)\n",
    "    df_w1 = pd.DataFrame.from_dict(w1)\n",
    "\n",
    "\n",
    "################### ac\n",
    "    print(trial)\n",
    "    print(\"Without perturbation\")\n",
    "    print(accuracy(Y_train,X_test,W1, b1,W2,b2))\n",
    "    print(\"\")\n",
    "    print('###############################')\n",
    "##########################################33\n",
    "\n",
    "###################### write weights\n",
    "    df1 = pd.concat([df_w1,df_w2],axis=1).reindex(df_w1.index)\n",
    "    df1 = df1[:34850]\n",
    "   \n",
    "\n",
    "    \n",
    "   \n",
    "    write_csv(df1,'pure',trial,path)\n",
    "    # write_csv(df2,'perturbed',trial,path)\n",
    "    write_csv(df_activations,'activations_pure',trial,path)\n",
    "\n",
    "    kwargs = dict(alpha=0.5, bins=150)\n",
    "\n",
    "    plt.figure(figsize=(30,20))\n",
    "    plt.hist(activations[1-1], **kwargs, color='g', label='0')\n",
    "    plt.hist(activations[2-1], **kwargs, color='b', label='1')\n",
    "    plt.hist(activations[3-1], **kwargs, color='r', label='2')\n",
    "    plt.hist(activations[4-1], **kwargs, color='c', label='3')\n",
    "    plt.gca().set(title='Frequency Histogram of Neuron Ops', ylabel='Frequency')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{path+init_words}\\\\activations_pure\\\\activations_pure{trial}_pure.png', bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train,X_dev,Y_dev = prepare_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in range(1,trials+1):\n",
    "    run_network(trial,X_train,Y_train,X_dev,Y_dev,alpha,num_iterations,init,perturb,lip_lr,loss)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37a27d0e5b469d6519fba8d674fca678a9e423d1818ec628dd8efc12286d08bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
